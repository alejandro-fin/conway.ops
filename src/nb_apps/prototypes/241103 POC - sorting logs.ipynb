{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169bfbb1-ea53-407b-8f4c-6d9cd05be3e4",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">POC - Sorting log files</h1>\n",
    "<p>As part of the introduction of asyncio in Conway, logs are no longer appearing in the order of algorithmic declaration,\n",
    "but in the order of execution, which can make it hard to read for situations like test cases</p>\n",
    "\n",
    "<p>To address that, in November 2024 a number of \"labels\" (to borrow the Grafana-like term) were added to the logs to record the ancestry of stack calls that lead to asyncio calls. This creates logs that are still \"unsorted\" (i.e., not in the order of algorithmic declaration), but which have enough context information (the \"labels\") to permit re-sorting them.</p>\n",
    "\n",
    "<p>This notebook was added to prototype such sorting.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff27003-d88a-45e0-b930-1d72fc1da3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONWAY installation:            \u001b[34m\u001b[7m    conway_fork    \u001b[0m\n",
      "Jupyter using repo[branch]:  \u001b[32m\u001b[7m    conway.ops[afin-dev]    \u001b[0m\n",
      "Installation path:           \u001b[34m\u001b[7m    /home/alex/consultant1@CCL/dev/conway_fork    \u001b[0m\n",
      "Application:                 \u001b[32m\u001b[7m    <class 'chassis_nb_application.Chassis_NB_Application'>    \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os                                                               as _os\n",
    "import sys\n",
    "sys.path.append(_os.path.dirname(_os.getcwd())) # So we can import tvm_notebook_utils\n",
    "import chassis_nb_utils\n",
    "NBU                       = chassis_nb_utils.Chassis_NB_Utils()\n",
    "DFU                       = NBU.DFU\n",
    "T0                        = NBU.time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad7ddc2-2f7f-4231-9837-a8a02ad02066",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_FOLDER                = \"/var/log/ccl/consultant1@CCL/dev/conway_fork/ConwayTestApp\"\n",
    "LOG_FILE                   = \"241102.222513_ConwayTestApp.log\"\n",
    "LOG_PATH                   = f\"{LOGS_FOLDER}/{LOG_FILE}\"\n",
    "SCHEDULING_CONTEXT         = \"scheduling_context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72168eba-81b8-4f46-ac6c-8dd87c492624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as _json\n",
    "import re as _re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d395ff-be48-4f08-900c-afe7b9bff6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the file in read mode\n",
    "data_l = []\n",
    "with open(LOG_PATH, 'r') as file:\n",
    "    # Read the file line by line\n",
    "    for line in file:\n",
    "        data = _json.loads(line)\n",
    "        data_l.append(data)\n",
    "len(data_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac196ec-fe0f-4fbd-b839-303f28a1e4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'message': \"Created 'integration' branch in 'scenario_8002.scenarios' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.scenarios/git/refs/heads/integration\",\n",
       "  'labels': {'scheduling_context': {'timestamp': '2.278 sec',\n",
       "    'thread': 'MainThread',\n",
       "    'task': 'Task-36',\n",
       "    'source': 'repo_manipulation_test_case:100'},\n",
       "   'timestamp': '4.186 sec',\n",
       "   'thread': 'MainThread',\n",
       "   'task': 'Task-38',\n",
       "   'source': 'repo_manipulation_test_case:195'}},\n",
       " dict)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_l[10], type(data_l[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72e70ec4-ccad-44fe-b349-159f5b05d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _extract_task_timestamps(data_l):\n",
    "    '''\n",
    "    Creates and returns a dictionary with metadata about the log lines. The returned dictionary\n",
    "    will have the task ids as key. For example, \"Task-36\" could be a key.\n",
    "    \n",
    "    The values will be a subdictionary with two entries:\n",
    "    * An entry \"timestamps\" with values being list of timestamps (such as \"2.101 sec\") that appear in the log file for such a task,\n",
    "      sorted in ascending order\n",
    "\n",
    "    * An entry \"ancestors\" with values being a (possibly empty) list of the other tasks that are ancestors of this one, sorted\n",
    "      from immediate parent to parent's parent, and so on.\n",
    "        \n",
    "     The purpose of getting this list is a preliminary piece of information to correctly sort log lines.\n",
    "    \n",
    "     For example, the log lines for two \"leaf\" tasks (i.e., tasks that don't trigger other sub-tasks) should be sorted so that \n",
    "     lines for each task are adjacent, with the lines for the task that \"first appeared\" listed before the lines of the other task.\n",
    "     In this case, the determination of \"first appeared\" is made by taking the min of the list for such task in this result_dict.\n",
    "    '''\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    def _extract_recursively(labels):\n",
    "        '''\n",
    "        Inner method so taht we extrat not just the timestamp for the log line in question, but also move up the scheduling context\n",
    "        hierarchy, i.e., the timestamps of prior log lines that led to this one.\n",
    "        '''\n",
    "        task = labels['task']\n",
    "        timestamp = labels['timestamp']\n",
    "        if not task in result_dict.keys():\n",
    "            result_dict[task] = {\"timestamps\": [], \"ancestors\": []}\n",
    "        result_dict[task][\"timestamps\"].append(timestamp)\n",
    "\n",
    "        # Now make a recursive call if needed\n",
    "        if SCHEDULING_CONTEXT in labels.keys():\n",
    "            parent_labels = labels[SCHEDULING_CONTEXT]\n",
    "            _extract_recursively(parent_labels)\n",
    "            parent_task = parent_labels['task']\n",
    "            parent_ancestors = result_dict[parent_task]['ancestors']\n",
    "            ancestors_so_far = result_dict[task]['ancestors']\n",
    "            ancestors = list(set({parent_task}).union(set(parent_ancestors)).union(set(ancestors_so_far)))\n",
    "            result_dict[task]['ancestors'] = ancestors\n",
    "        \n",
    "\n",
    "    for datum in data_l:\n",
    "        labels = datum['labels']\n",
    "        _extract_recursively(labels)\n",
    "\n",
    "    # Now sort and avoid duplicates\n",
    "    for task in result_dict.keys():\n",
    "        ts_l = result_dict[task][\"timestamps\"]\n",
    "        # remove duplicates\n",
    "        ts_l = list(set(ts_l))\n",
    "        # sort\n",
    "        ts_l = sorted(ts_l, key=_timestamp_key)\n",
    "        result_dict[task][\"timestamps\"] = ts_l\n",
    "        \n",
    "    return result_dict\n",
    "\n",
    "def _timestamp_key(ts):\n",
    "    '''\n",
    "    This is used to sort lists of timestamps, such as those produced by _extract_task_timestamp for each task. When used as the key\n",
    "    for sorting, it ensures that a timestamp like \"11.344 sec\" appears after a timestamp like \"2.550 sec\", and not vice-versa as it would\n",
    "    be if the timestamps were sorted lexicographically as strings.\n",
    "    \n",
    "    :param ts: A timestamp produced by Conway logs, such as \"2.550 sec\"\n",
    "    :type ts: str\n",
    "    :returns: a float obtained by parsing the `ts` parameter. For example, if `ts` is \"2.550 sec\", then this function will return the number\n",
    "        2.550\n",
    "    :rtype: float\n",
    "    '''\n",
    "    REGEX = r\"(\\d+.\\d+) sec\"\n",
    "    m = _re.match(REGEX, ts)\n",
    "    return float(m[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "619f713b-de34-4644-8f43-7a0cf5927b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Not using an event loop': {'timestamps': ['0.612 sec',\n",
       "   '1.787 sec',\n",
       "   '11.266 sec'],\n",
       "  'ancestors': []},\n",
       " 'Task-38': {'timestamps': ['2.623 sec', '3.641 sec', '4.186 sec'],\n",
       "  'ancestors': ['Task-36']},\n",
       " 'Task-36': {'timestamps': ['2.266 sec',\n",
       "   '2.273 sec',\n",
       "   '2.278 sec',\n",
       "   '2.284 sec',\n",
       "   '2.288 sec',\n",
       "   '5.052 sec'],\n",
       "  'ancestors': []},\n",
       " 'Task-42': {'timestamps': ['2.752 sec', '4.078 sec', '4.530 sec'],\n",
       "  'ancestors': ['Task-36']},\n",
       " 'Task-39': {'timestamps': ['2.772 sec', '4.303 sec', '4.806 sec'],\n",
       "  'ancestors': ['Task-36']},\n",
       " 'Task-40': {'timestamps': ['2.797 sec', '3.752 sec', '4.242 sec'],\n",
       "  'ancestors': ['Task-36']},\n",
       " 'Task-41': {'timestamps': ['2.822 sec', '4.543 sec', '5.029 sec'],\n",
       "  'ancestors': ['Task-36']},\n",
       " 'Task-49': {'timestamps': ['5.080 sec',\n",
       "   '5.101 sec',\n",
       "   '5.120 sec',\n",
       "   '5.135 sec',\n",
       "   '5.145 sec',\n",
       "   '5.159 sec'],\n",
       "  'ancestors': []},\n",
       " 'Task-52': {'timestamps': ['6.042 sec',\n",
       "   '9.493 sec',\n",
       "   '9.746 sec',\n",
       "   '9.758 sec'],\n",
       "  'ancestors': ['Task-49']},\n",
       " 'Task-53': {'timestamps': ['6.075 sec',\n",
       "   '9.426 sec',\n",
       "   '9.763 sec',\n",
       "   '9.772 sec'],\n",
       "  'ancestors': ['Task-49']},\n",
       " 'Task-50': {'timestamps': ['6.104 sec',\n",
       "   '9.563 sec',\n",
       "   '9.780 sec',\n",
       "   '9.792 sec'],\n",
       "  'ancestors': ['Task-49']},\n",
       " 'Task-51': {'timestamps': ['6.132 sec',\n",
       "   '9.548 sec',\n",
       "   '9.799 sec',\n",
       "   '9.805 sec'],\n",
       "  'ancestors': ['Task-49']},\n",
       " 'Task-54': {'timestamps': ['6.155 sec',\n",
       "   '9.455 sec',\n",
       "   '9.725 sec',\n",
       "   '9.739 sec'],\n",
       "  'ancestors': ['Task-49']}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dict = _extract_task_timestamps(data_l)\n",
    "ts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77a8c33f-90a4-4b62-b143-691278555698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_line_key(ts_dict, log_line):\n",
    "    '''\n",
    "    Returns a sorting key to use for sorting lines created by a Conway Logger, so that the lines are re-sorted in terms of the order how\n",
    "    the code that triggers them is written, as opposed to the order in which that code is executed. The two may differ because under asyncio,\n",
    "    code may be written in the order in which tasks are submitted to the event queue, but then executed in a different, non-determinitic order.\n",
    "    \n",
    "    :param ts_dict: dictionary whose keys are asyncio task identifiers, and whose values are lists of timestamps at which that task appears,\n",
    "        sorted from earlier to latest timestamp.\n",
    "        \n",
    "        Example: \n",
    "\n",
    "        .. code::\n",
    "            \n",
    "            {'Not using an event loop': ['0.612 sec', '1.787 sec', '11.266 sec'],\n",
    "             'Task-38': ['2.623 sec', '3.641 sec', '4.186 sec'],\n",
    "             'Task-36': ['2.266 sec', '2.278 sec', '5.052 sec'],\n",
    "\n",
    "    :type ts_dict: dict\n",
    "\n",
    "    :param log_line: a line of log output from the Conway Logger, parsed as a JSON string that is represented as a dictionary.\n",
    "        Example:\n",
    "\n",
    "        .. code::\n",
    "        \n",
    "            {'message': \"Created 'integration' branch in 'scenario_8002.scenarios' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.scenarios/git/refs/heads/integration\",\n",
    "              'labels': {'scheduling_context': {'timestamp': '2.278 sec',\n",
    "                'thread': 'MainThread',\n",
    "                'task': 'Task-36',\n",
    "                'source': 'repo_manipulation_test_case:100'},\n",
    "               'timestamp': '4.186 sec',\n",
    "               'thread': 'MainThread',\n",
    "               'task': 'Task-38',\n",
    "               'source': 'repo_manipulation_test_case:195'}}\n",
    "               \n",
    "    :type log_line: dict\n",
    "        \n",
    "    '''\n",
    "    # We will be \"padding\" the keys so that they are dimensionally equal. For example, if we have a key like (12, 40) and another one\n",
    "    # like ((3, 5), (5,7)), then we will pad the first key to be ((12, 40), (0,0)) so that both keys are dimensionally equal.\n",
    "    # To do this, we need to compute just how much padding must be done per key. This depends on just how many ancestors line has \n",
    "    # relative to how many ancestors others lines have, i.e., the gap between a line's number of ancestors and the maximum number\n",
    "    # of ancestors across all logs.\n",
    "    # Hence we compute:\n",
    "    #\n",
    "    max_nb_ancestors = max([len(ts_dict[task][\"ancestors\"]) for task in ts_dict.keys()])\n",
    "\n",
    "    \n",
    "    # Labels may exist hierarchically, in the sense that a labels dict may have a \"parent labels dict\" in the form of the scheduling context.\n",
    "    #\n",
    "    # So the sorting policy is:\n",
    "    #   1. For a line with multiple labels dicts, sort lexicographically starting with the labels dict highest in the hierarchy\n",
    "    #   2. A labels dict A precedes a labels dict B if the first timestamp for A's task precedes the first timestamp for B's task.\n",
    "    #      Here the meaning of \"first timestamp\" for a task is as determined by the `ts_dict` parameter, i.e., the \"first timestamp\" for\n",
    "    #      a task may be different (and earlier) than the timestamp for that task in the log line we are creating a key for.\n",
    "    #\n",
    "    labels = log_line['labels']\n",
    "\n",
    "    def _labels_key(labels):\n",
    "        task = labels['task']\n",
    "        timestamp = labels['timestamp']\n",
    "        if task != \"Not using an event loop\":\n",
    "            min_timestamp = ts_dict[task][\"timestamps\"][0]\n",
    "        else:\n",
    "            min_timestamp = timestamp\n",
    "\n",
    "        return (_timestamp_key(min_timestamp), _timestamp_key(timestamp))\n",
    "\n",
    "    def _hierarchical_key(labels):\n",
    "        if not SCHEDULING_CONTEXT in labels.keys():\n",
    "            return _labels_key(labels)\n",
    "        else:\n",
    "            parent_labels = labels[SCHEDULING_CONTEXT]\n",
    "            parent_key = _hierarchical_key(parent_labels)\n",
    "            child_key = _labels_key(labels)\n",
    "            return (parent_key, child_key)\n",
    "\n",
    "    padding_needed = max_nb_ancestors - len(ts_dict[labels['task']]['ancestors'])\n",
    "\n",
    "    unpadded_key = _hierarchical_key(labels)\n",
    "    key = unpadded_key\n",
    "    for idx in range(padding_needed):\n",
    "        key = (key, (0,0))\n",
    "\n",
    "    #return _labels_key(labels)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5ba08ec-6e01-4f4b-97ab-847d54e61653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.612, 0.612), (0, 0))\n",
      "((1.787, 1.787), (0, 0))\n",
      "((2.266, 2.278), (2.623, 2.623))\n",
      "((2.266, 2.284), (2.752, 2.752))\n",
      "((2.266, 2.273), (2.772, 2.772))\n",
      "((2.266, 2.288), (2.797, 2.797))\n",
      "((2.266, 2.266), (2.822, 2.822))\n",
      "((2.266, 2.278), (2.623, 3.641))\n",
      "((2.266, 2.288), (2.797, 3.752))\n",
      "((2.266, 2.284), (2.752, 4.078))\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(_log_line_key(ts_dict, data_l[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3c75a-6c37-4abf-b472-c68708ed058a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa71fd23-d673-43e0-842a-b81ec8c7159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 5), (0, 0)), ((3, 50), (0, 0)), ((12, 40), (0, 0)), ((12, 40), (2, 1))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([((12, 40), (0,0)), ((3, 50), (0,0)), ((3, 5), (0,0)), ((12, 40), (2, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa892d24-c94e-44b5-97f3-0477fc84b7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data_l = sorted(data_l, key= lambda line: _log_line_key(ts_dict, line))\n",
    "len(sorted_data_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc077ee-56f3-41cc-b19c-16927e745587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f85b15be-1897-45d0-b34a-3527ce007a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "foo = \"[2.266 sec Task-36]\"\n",
    "x.append(foo)\n",
    "foo in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c03cf7f-ae68-4e14-8e53-6a70fb1c5154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.612 sec Not using an event loop]\t--------- Starting Test Scenario 8001 [round=0] ---------\n",
      "[1.787 sec Not using an event loop]\t--------- Starting Test Scenario 8002 [round=0] ---------\n",
      "[2.266 sec Task-36]\n",
      "\t[2.822 sec Task-41]\tRemoved pre-existing repo 'scenario_8002.svc' so we can re-create it - response was null\n",
      "\t[4.543 sec Task-41]\tCreated repo 'scenario_8002.svc' with URL https://github.com/testrobot-ccl/scenario_8002.svc\n",
      "\t[5.029 sec Task-41]\tCreated 'integration' branch in 'scenario_8002.svc' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.svc/git/refs/heads/integration\n",
      "[2.273 sec Task-36]\n",
      "\t[2.772 sec Task-39]\tRemoved pre-existing repo 'scenario_8002.test' so we can re-create it - response was null\n",
      "\t[4.303 sec Task-39]\tCreated repo 'scenario_8002.test' with URL https://github.com/testrobot-ccl/scenario_8002.test\n",
      "\t[4.806 sec Task-39]\tCreated 'integration' branch in 'scenario_8002.test' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.test/git/refs/heads/integration\n",
      "[2.278 sec Task-36]\n",
      "\t[2.623 sec Task-38]\tRemoved pre-existing repo 'scenario_8002.scenarios' so we can re-create it - response was null\n",
      "\t[3.641 sec Task-38]\tCreated repo 'scenario_8002.scenarios' with URL https://github.com/testrobot-ccl/scenario_8002.scenarios\n",
      "\t[4.186 sec Task-38]\tCreated 'integration' branch in 'scenario_8002.scenarios' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.scenarios/git/refs/heads/integration\n",
      "[2.284 sec Task-36]\n",
      "\t[2.752 sec Task-42]\tRemoved pre-existing repo 'scenario_8002.ops' so we can re-create it - response was null\n",
      "\t[4.078 sec Task-42]\tCreated repo 'scenario_8002.ops' with URL https://github.com/testrobot-ccl/scenario_8002.ops\n",
      "\t[4.530 sec Task-42]\tCreated 'integration' branch in 'scenario_8002.ops' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.ops/git/refs/heads/integration\n",
      "[2.288 sec Task-36]\n",
      "\t[2.797 sec Task-40]\tRemoved pre-existing repo 'scenario_8002.docs' so we can re-create it - response was null\n",
      "\t[3.752 sec Task-40]\tCreated repo 'scenario_8002.docs' with URL https://github.com/testrobot-ccl/scenario_8002.docs\n",
      "\t[4.242 sec Task-40]\tCreated 'integration' branch in 'scenario_8002.docs' with URL https://api.github.com/repos/testrobot-ccl/scenario_8002.docs/git/refs/heads/integration\n",
      "[5.052 sec Task-36]\tList of remote repos re-created: ['scenario_8002.scenarios', 'scenario_8002.docs', 'scenario_8002.ops', 'scenario_8002.test', 'scenario_8002.svc']\n",
      "[5.080 sec Task-49]\tWill set up repos ['scenario_8002.svc', 'scenario_8002.test', 'scenario_8002.scenarios', 'scenario_8002.ops', 'scenario_8002.docs'] after applying filter None\n",
      "[5.101 sec Task-49]\n",
      "\t[6.132 sec Task-51]\t\t... cloned repo 'scenario_8002.svc' ...\n",
      "\t[9.548 sec Task-51]\t\t... created branches ['testrobot'] for repo 'scenario_8002.svc' ...\n",
      "\t[9.799 sec Task-51]\t\tConfiguring repo 'scenario_8002.svc' ... completed in 0.24 sec\n",
      "\t[9.805 sec Task-51]\tSetting up repo 'scenario_8002.svc' completed in 4.63 sec\n",
      "[5.120 sec Task-49]\n",
      "\t[6.155 sec Task-54]\t\t... cloned repo 'scenario_8002.test' ...\n",
      "\t[9.455 sec Task-54]\t\t... created branches ['testrobot'] for repo 'scenario_8002.test' ...\n",
      "\t[9.725 sec Task-54]\t\tConfiguring repo 'scenario_8002.test' ... completed in 0.23 sec\n",
      "\t[9.739 sec Task-54]\tSetting up repo 'scenario_8002.test' completed in 4.56 sec\n",
      "[5.135 sec Task-49]\n",
      "\t[6.075 sec Task-53]\t\t... cloned repo 'scenario_8002.scenarios' ...\n",
      "\t[9.426 sec Task-53]\t\t... created branches ['testrobot'] for repo 'scenario_8002.scenarios' ...\n",
      "\t[9.763 sec Task-53]\t\tConfiguring repo 'scenario_8002.scenarios' ... completed in 0.31 sec\n",
      "\t[9.772 sec Task-53]\tSetting up repo 'scenario_8002.scenarios' completed in 4.60 sec\n",
      "[5.145 sec Task-49]\n",
      "\t[6.104 sec Task-50]\t\t... cloned repo 'scenario_8002.ops' ...\n",
      "\t[9.563 sec Task-50]\t\t... created branches ['testrobot'] for repo 'scenario_8002.ops' ...\n",
      "\t[9.780 sec Task-50]\t\tConfiguring repo 'scenario_8002.ops' ... completed in 0.19 sec\n",
      "\t[9.792 sec Task-50]\tSetting up repo 'scenario_8002.ops' completed in 4.62 sec\n",
      "[5.159 sec Task-49]\n",
      "\t[6.042 sec Task-52]\t\t... cloned repo 'scenario_8002.docs' ...\n",
      "\t[9.493 sec Task-52]\t\t... created branches ['testrobot'] for repo 'scenario_8002.docs' ...\n",
      "\t[9.746 sec Task-52]\t\tConfiguring repo 'scenario_8002.docs' ... completed in 0.20 sec\n",
      "\t[9.758 sec Task-52]\tSetting up repo 'scenario_8002.docs' completed in 4.58 sec\n",
      "[11.266 sec Not using an event loop]\tCreating branch report completed in 1.46 sec\n"
     ]
    }
   ],
   "source": [
    "def _format_labels(labels):\n",
    "    task = labels['task']\n",
    "    ts = labels['timestamp']\n",
    "    msg = datum['message']\n",
    "\n",
    "    padding_needed = len(ts_dict[task]['ancestors'])\n",
    "    padding = \"\\t\"*padding_needed\n",
    "\n",
    "    prefix = f\"{padding}[{ts} {task}]\"\n",
    "    return prefix\n",
    "\n",
    "def _format_ancestors(labels):\n",
    "    if not SCHEDULING_CONTEXT in labels.keys():\n",
    "        return []\n",
    "    else:\n",
    "        parent_labels = labels[SCHEDULING_CONTEXT]\n",
    "        parent_formatted_ancestors = _format_ancestors(parent_labels)\n",
    "        formatted_ancestors = parent_formatted_ancestors.copy()\n",
    "        formatted_ancestors.extend([_format_labels(parent_labels)])\n",
    "        return formatted_ancestors\n",
    "\n",
    "already_seen = []\n",
    "for datum in sorted_data_l:\n",
    "    \n",
    "    labels = datum['labels']\n",
    "\n",
    "    for txt in _format_ancestors(labels):\n",
    "        if not txt in already_seen:\n",
    "            print(txt)\n",
    "            already_seen.append(txt)\n",
    "\n",
    "    msg = datum['message']\n",
    "    prefix = _format_labels(labels)\n",
    "    print(f\"{prefix}\\t{msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d0d4d-41aa-41fa-9a19-c46631a21131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
